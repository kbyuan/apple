{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs260rec_final",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txrj7i9Rl_HS",
        "colab_type": "code",
        "outputId": "b650964c-0f8f-4335-d1ae-9d24a868b389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "##Pytorch Req Code\n",
        "\n",
        "import torch\n",
        "import scipy.sparse as sparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests, zipfile, io\n",
        "import random, time, sys\n",
        "from pandas.compat import StringIO\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "!pip install implicit\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#r = requests.get('http://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip')\n",
        "#z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "#z.extractall()\n",
        "#item = pd.read_csv(\"./user_artists.dat\", sep='\\s+')\n",
        "\n",
        "#read data into DataFram\n",
        "Main_File = './user_artists.dat'\n",
        "#Lookup_File = './artists.dat'\n",
        "\n",
        "#dfnp = np.genfromtxt(Main_File, skip_header=1) # Skips the header and put numbers into array\n",
        "dfnp = pd.read_csv('https://s3.us-east-2.amazonaws.com/rudydata/user_artist.csv',sep= \",\", engine='python' ).values\n",
        "UATensor = torch.Tensor(dfnp) # Converts dataset to Tensor\n",
        "\n",
        "# Setting up the sparse matrix\n",
        "user_artist = UATensor[:,:2].t().type(torch.LongTensor) # Sets up the User & Artist index as Long Tensor for input to sparse function\n",
        "weight = UATensor.t()[2] # Sets up the number of times a user listens to an artist as a Float Tensor for input to sparse function\n",
        "max_user = int(max(user_artist[0]).item()) + 1 # Max user + 1 for sparse matrix size\n",
        "max_artist = int(max(user_artist[1]).item()) + 1 # Max artist + 1 for sparse matrix size\n",
        "listens_sparse = torch.sparse.FloatTensor(user_artist, weight, torch.Size([max_user, max_artist])) # Sparse Matrix; .to_dense(); .to_sparse()\n",
        "\n",
        "nonzeros = listens_sparse._nnz() # Checks the number of non-zero items; resulted in 92,834 and matches\n",
        "total_elements = listens_sparse.nelement() # Number of elements in the sparse matrix; resulted in 39,385,346\n",
        "sparsity = 1 - nonzeros / total_elements # Percentage of how sparse the matrix is; resulted in 99.764293%. \n",
        "                                           # Not quite matching because some users have not listened to anything.\n",
        "                                           # Should these users be excluded?\n",
        "\n",
        "# Creating Train and Test Set\n",
        "pct_test = 0.2 # The percentage of user-artist interactions that you want to mask in the training set.\n",
        "\n",
        "# Make a copy of the original set to be the test set, and store the test set as a binary preference matrix\n",
        "test_set = torch.sparse.FloatTensor(user_artist, torch.ones(weight.size()), torch.Size([max_user, max_artist]))\n",
        "\n",
        "num_samples = torch.randperm(nonzeros) # Randomly assigns a row a number between 0 to number of idices\n",
        "UATensor_smpl = UATensor[num_samples > pct_test * nonzeros] # Samples 1 - pct_test of UATensor, so that this masks pct_test of the training set\n",
        "user_artist_smpl = UATensor_smpl[:,:2].t().type(torch.LongTensor) # Sets up the user_artist of the sample\n",
        "weight_smpl = UATensor_smpl.t()[2] # Sets up the weight of the sample\n",
        "training_set = torch.sparse.FloatTensor(user_artist_smpl, weight_smpl, torch.Size([max_user, max_artist])) # Create training set with sample size\n",
        "\n",
        "# --- ALS Model --- #\n",
        "print(\"begin model\")\n",
        "\n",
        "# Parameters for ALS Model\n",
        "lambda_val = 0.01 # Used for regularization. Increasing this value may increase bias but decrease variance\n",
        "alpha = 2 # Associated with confidence matrix where Cui = 1 + alpha*Rui. Decreasing this will decrease the variability in confidence between various ratings.\n",
        "iterations = 10 # The number of times to alternate between both user feature vector and artist feature vector in ALS. \n",
        "                # More iterations will allow better convergence at the cost of increased computation.\n",
        "rank_size = 15 # The number of latent features in the user/artist feature vectors. Increasing the number of features may overfit but could reduce bias.\n",
        "seed = 0 # Set the seed for reproducible reseults\n",
        "\n",
        "# Set up Confidence Matrix\n",
        "conf = (alpha * training_set).to_dense().to(device) # To allow the matrix to stay sparse, I will add one later when each row is taken and converted to dense.\n",
        "pref_all = conf.clone()\n",
        "pref_all[pref_all != 0] = 1 # Create binarized preference vector\n",
        "\n",
        "# initialize our X/Y feature vectors randomly with a set seed\n",
        "X = torch.rand(max_user, rank_size).to(device) # Random numbers in a m x rank shape\n",
        "Y = torch.rand(max_artist, rank_size).to(device) # Normally this would be rank x n but we can \n",
        "                                                  # transpose at the end. Makes calculation more simple.\n",
        "X_eye = torch.eye(max_user).to(device)\n",
        "Y_eye = torch.eye(max_artist).to(device)\n",
        "lambda_eye = lambda_val * torch.eye(rank_size).to(device) # Our regularization term lambda*I.\n",
        "\n",
        "# Begin iterations\n",
        "for iter_step in range(iterations): # Iterate back and forth between solving X given fixed Y and vice versa\n",
        "  start = time.time()\n",
        "  \n",
        "  # Compute yTy and xTx at beginning of each iteration to save computing time\n",
        "  yTy = Y.t().mm(Y).to(device)\n",
        "  xTx = X.t().mm(X).to(device)\n",
        "  \n",
        "  # Begin iteration to solve for X based on fixed Y\n",
        "  for u in range(max_user):\n",
        "    conf_samp = conf[u,:] # Grab user row from confidence matrix and convert to dense\n",
        "    pref = pref_all[u,:]\n",
        "    CuI = conf_samp.diag() # Get Cu - I term, don't need to subtract 1 since we never added it\n",
        "    yTCuIY = Y.t().mm(CuI).mm(Y) # This is the yT(Cu-I)Y term\n",
        "    yTCupu = Y.t().mm(CuI + Y_eye).mm(pref.unsqueeze(0).t()) # This is the yTCuPu term, where we add the eye back in Cu - I + I = Cu\n",
        "    X[u] = (yTy + yTCuIY + lambda_eye).inverse().mm(yTCupu).t() # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu\n",
        "    \n",
        "  # Begin iteration to solve for Y based on fixed X \n",
        "  for a in range(max_artist):\n",
        "    conf_samp = conf[:,a] # transpose to get it in row format and convert to dense\n",
        "    pref =  pref_all[:,a]\n",
        "    CiI = conf_samp.diag() # Get Ci - I term, don't need to subtract 1 since we never added it\n",
        "    xTCiIX = X.t().mm(CiI).mm(X) # This is the xT(Cu-I)X term\n",
        "    xTCiPi = X.t().mm(CiI + X_eye).mm(pref.unsqueeze(0).t()) # This is the xTCiPi term\n",
        "    Y[a] = (xTx + xTCiIX + lambda_eye).inverse().mm(xTCiPi).t() # Solve for Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi, equation 5 from the paper\n",
        "    \n",
        "  print(iter_step, time.time() - start)\n",
        "  \n",
        "def auc_score(predictions, test):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
        "    return metrics.auc(fpr, tpr)   \n",
        "  \n",
        "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
        "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
        "    popularity_auc = [] # To store popular AUC scores\n",
        "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
        "    item_vecs = predictions[1]\n",
        "    for user in altered_users: # Iterate through each user that had an item altered\n",
        "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
        "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
        "        # Get the predicted values based on our user/item vectors\n",
        "        user_vec = predictions[0][user,:]\n",
        "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
        "        # Get only the items that were originally zero\n",
        "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
        "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
        "        # Select the binarized yes/no interaction pairs from the original full data\n",
        "        # that align with the same pairs in training \n",
        "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
        "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
        "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
        "    # End users iteration\n",
        "    \n",
        "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
        "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
        "\n",
        "# To remove artists where they were never listened to from dataset\n",
        "test_set_np = test_set.to_dense().numpy()\n",
        "a_count = test_set_np.sum(axis=0)\n",
        "a_zeros = np.where(a_count == 0)[0]\n",
        "\n",
        "# Sets up inputs for Calc Mean AUC\n",
        "train_np = sparse.csr_matrix(np.delete(training_set.to_dense().numpy(), a_zeros, axis=1))\n",
        "altered_users = np.unique(UATensor[num_samples <= pct_test * nonzeros][:,0].int().numpy())\n",
        "user_vecs = X.to('cpu').numpy()\n",
        "item_vecs = np.delete(Y.t().to('cpu').numpy(), a_zeros, axis=1)\n",
        "test_np = sparse.csr_matrix(np.delete(test_set_np, a_zeros, axis=1))\n",
        "\n",
        "# AUC for our recommender system\n",
        "calc_mean_auc(train_np, altered_users, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs)], test_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: implicit in /usr/local/lib/python3.6/dist-packages (0.3.8)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from implicit) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from implicit) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from implicit) (1.14.6)\n",
            "begin model\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}